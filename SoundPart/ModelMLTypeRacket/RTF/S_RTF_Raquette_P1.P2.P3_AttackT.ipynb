{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTF Model for predicting racket type using P1, P2 and P3, based on attack time - Sound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description\n",
    "\n",
    "This notebook implements a Random Tree Forest (RTF) model to predict the type of a racket (RB, RO, RR, RV) based on sound features extracted from audio files. The workflow involves reading `.wav` files, extracting frequency peaks using FFT, and incorporating the attack time as an additional feature. The attack time is calculated as the duration it takes for the signal to reach a specified amplitude threshold. These features are used to train the model, and its performance is evaluated using accuracy metrics and visualized through scatter plots and confusion matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Tools Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reach the project root\n",
    "notebook_path = os.path.abspath('')\n",
    "project_root = os.path.abspath(os.path.join(notebook_path, '../../../'))\n",
    "functions_path = os.path.join(project_root, 'Functions')\n",
    "\n",
    "# Add Functions folder\n",
    "if functions_path not in sys.path:\n",
    "    sys.path.append(functions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions\n",
    "\n",
    "from attack_time_from_signal import attack_time_from_signal\n",
    "from extractPeakFromSignal import extractPeakFromSignal\n",
    "from readWavFolder import readWavFolder\n",
    "from spectrumFromSignal import spectrumFromSignal\n",
    "from spectrumFromWav import spectrumFromWav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of racket types\n",
    "raquetteTypeList = {\"RB\":0,\"RO\":1,\"RR\":2,\"RV\":3}\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "for n_peak in range(5, 101, 5):\n",
    "    X_peaksHz = []\n",
    "    X_peaksAmplitude = []\n",
    "    X_attack_time = []\n",
    "    Y_Label = []\n",
    "    attack_times = []\n",
    "    #print(\"Nbr_peak\", n_peak)\n",
    "\n",
    "    # Create a DataFrame to store details of each wav file\n",
    "    wav_files_data = []\n",
    "\n",
    "    # Process each folder (P1, P2, P3)\n",
    "    for folder, folder_path in [(\"P1\", \"../../../Data/Sound/P1\"), \n",
    "                                (\"P2\", \"../../../Data/Sound/P2\"), \n",
    "                                (\"P3\", \"../../../Data/Sound/P3\")]:\n",
    "        sample_rates, wav_files, file_names = readWavFolder(folder_path)\n",
    "        \n",
    "        for sample_rate, wav_file, file_name in zip(sample_rates, wav_files, file_names):\n",
    "            wav_files_data.append({\n",
    "                \"Folder\": folder,\n",
    "                \"File_Name\": file_name,\n",
    "                \"Sample_Rate\": sample_rate,\n",
    "                \"Signal\": wav_file\n",
    "            })\n",
    "\n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    wav_files_df = pd.DataFrame(wav_files_data)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    #print(wav_files_df)\n",
    "\n",
    "    spectrumVect = []\n",
    "\n",
    "    # For each wav file, extract its spectrum, filter it between 150 and 1000 Hz, and take the top n peaks\n",
    "    for i in range(len(wav_files_df[\"Signal\"])):\n",
    "        if \"C\" in wav_files_df[\"File_Name\"][i]:\n",
    "            if 'RB' in wav_files_df[\"File_Name\"][i]:\n",
    "                raquetteType = 'RB'\n",
    "            elif 'RR' in wav_files_df[\"File_Name\"][i]:\n",
    "                raquetteType = 'RR'\n",
    "            elif 'RO' in wav_files_df[\"File_Name\"][i]:\n",
    "                raquetteType = 'RO'\n",
    "            elif 'RV' in wav_files_df[\"File_Name\"][i]:\n",
    "                raquetteType = 'RV'\n",
    "\n",
    "            # Extract the spectrum from the wav file\n",
    "            spectrum, freqs = spectrumFromSignal(wav_files_df[\"Signal\"][i], wav_files_df[\"Sample_Rate\"][i])\n",
    "            spectrumVect.append(freqs)\n",
    "\n",
    "            peaks, peak_values = extractPeakFromSignal(signal=spectrum, num_peaks=n_peak)\n",
    "\n",
    "            X_peaksHz.append(peaks)\n",
    "            X_peaksAmplitude.append(peak_values)\n",
    "            Y_Label.append(raquetteType)\n",
    "\n",
    "            # Calcul of attack time\n",
    "            row = wav_files_df.iloc[i]\n",
    "            attack_time = attack_time_from_signal(row[\"Signal\"], row[\"Sample_Rate\"])\n",
    "            attack_times.append(attack_time)\n",
    "\n",
    "    # Normalize the attack times\n",
    "    X_attack_time = np.array(attack_times).reshape(-1, 1)\n",
    "    X_attack_time = (X_attack_time - X_attack_time.min()) / (X_attack_time.max() - X_attack_time.min())\n",
    "\n",
    "    # Ensure all arrays in X_peaksHz have the same length\n",
    "    max_length = max(max(len(peaks) for peaks in X_peaksHz), max(len(amps) for amps in X_peaksAmplitude))\n",
    "    X_peaksHz_padded = np.array([np.pad(peaks, (0, max_length - len(peaks)), constant_values=0) for peaks in X_peaksHz])\n",
    "    X_peaksAmplitude_padded = np.array([np.pad(amps, (0, max_length - len(amps)), constant_values=0) for amps in X_peaksAmplitude])\n",
    "\n",
    "    # Combine the frequencies and amplitudes into a single feature matrix\n",
    "    X = np.hstack((X_peaksHz_padded, X_attack_time))\n",
    "\n",
    "    # Encode string labels into integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(Y_Label)\n",
    "\n",
    "    # Diviser les données en ensembles d'entraînement et de test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     n_peak  n_estimators  max_depth  min_samples_split  accuracy_train  \\\n",
      "75      100            60        NaN                  2        1.000000   \n",
      "13      100            10       40.0                  5        0.968619   \n",
      "1       100            10        NaN                  5        0.968619   \n",
      "69      100            50       30.0                  2        1.000000   \n",
      "66      100            50       20.0                  2        1.000000   \n",
      "..      ...           ...        ...                ...             ...   \n",
      "122     100            90        NaN                 10        0.956067   \n",
      "123     100            90       10.0                  2        0.997908   \n",
      "33      100            30       10.0                  2        0.995816   \n",
      "48      100            40       10.0                  2        0.997908   \n",
      "3       100            10       10.0                  2        0.976987   \n",
      "\n",
      "     accuracy_test  \n",
      "75        0.675000  \n",
      "13        0.675000  \n",
      "1         0.675000  \n",
      "69        0.675000  \n",
      "66        0.675000  \n",
      "..             ...  \n",
      "122       0.633333  \n",
      "123       0.633333  \n",
      "33        0.625000  \n",
      "48        0.616667  \n",
      "3         0.616667  \n",
      "\n",
      "[150 rows x 6 columns]\n",
      "Results have been saved to 'S_RTF_Racket_P1.P2.P3_AttackT.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Random Forest algorithm parameters\n",
    "n_estimators_range = range(10, 101, 10)  # Number of trees between 10 and 100\n",
    "max_depth_range = [None, 10, 20, 30, 40]  # Different depths\n",
    "min_samples_split_range = [2, 5, 10]  # Minimum number to divide a node\n",
    "min_samples_leaf_range = [1, 2, 4]  # Minimum number of samples in a sheet\n",
    "max_features_range = ['sqrt', 'log2', None]  # Number of features per tree\n",
    "\n",
    "# Test all the combinations of parameters\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_depth in max_depth_range:\n",
    "        for min_samples_split in min_samples_split_range:\n",
    "            # Create and train the Random Forest model\n",
    "            rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                        min_samples_split=min_samples_split, random_state=42)\n",
    "            rf.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate on the test set\n",
    "            y_pred = rf.predict(X_test)\n",
    "            accuracy_test = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # Evaluate on the training set\n",
    "            y_train_pred = rf.predict(X_train)\n",
    "            accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "            # Add the results to the list\n",
    "            results.append({\n",
    "                'n_peak': n_peak,\n",
    "                'n_estimators': n_estimators,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'accuracy_train': accuracy_train,\n",
    "                'accuracy_test': accuracy_test\n",
    "            })\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort the results by accuracy_test in descending order\n",
    "sorted_results_df = results_df.sort_values(by='accuracy_test', ascending=False)\n",
    "\n",
    "print(sorted_results_df)\n",
    "\n",
    "# Register the best parameters in a CSV file\n",
    "sorted_results_df.to_csv(\"S_RTF_Racket_P1.P2.P3_AttackT.csv\", index=False)\n",
    "\n",
    "print(\"Results have been saved to 'S_RTF_Racket_P1.P2.P3_AttackT.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
